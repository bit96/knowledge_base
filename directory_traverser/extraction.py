#!/usr/bin/env python3
"""
æå–æ¨¡å—
å¤„ç†é¡µé¢ä¿¡æ¯æå–ã€æ•°æ®è·å–ç­‰åŠŸèƒ½
"""

import time
from datetime import datetime
from typing import Optional, Dict, List, Set
from selenium.webdriver.common.by import By
from urllib.parse import urlparse


class ExtractionMixin:
    """æ•°æ®æå–åŠŸèƒ½æ··å…¥ç±»"""
    
    def extract_page_info(self) -> Optional[Dict]:
        """æå–å½“å‰é¡µé¢ä¿¡æ¯"""
        try:
            start_time = time.time()
            
            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            self.wait.until(lambda driver: driver.execute_script("return document.readyState") == "complete")
            
            current_url = self.driver.current_url
            page_title = self.driver.title
            response_time = time.time() - start_time
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å†…å®¹é¡µé¢
            if not page_title or page_title.strip() == "":
                return None
            
            page_info = {
                'url': current_url,
                'title': page_title,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'response_time': round(response_time, 2)
            }
            
            self.logger.debug(f"æå–é¡µé¢ä¿¡æ¯: {page_title[:50]}...")
            return page_info
            
        except Exception as e:
            self.logger.error(f"æå–é¡µé¢ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _diagnose_current_page(self):
        """è¯Šæ–­å½“å‰é¡µé¢ï¼Œå¸®åŠ©ç”¨æˆ·äº†è§£é—®é¢˜"""
        try:
            current_url = self.driver.current_url
            page_title = self.driver.title
            
            # åˆ†æé¡µé¢ä¸­çš„æ‰€æœ‰é“¾æ¥
            all_links = self.driver.find_elements(By.TAG_NAME, "a")
            
            # ç»Ÿè®¡å·¦ä¾§åŒºåŸŸçš„é“¾æ¥
            left_links = []
            for link in all_links:
                try:
                    if link.is_displayed():
                        location = link.location
                        href = link.get_attribute('href')
                        text = link.text.strip()
                        if location['x'] < 400 and href and text:
                            left_links.append({
                                'text': text,
                                'href': href,
                                'x': location['x'],
                                'y': location['y']
                            })
                except:
                    continue
            
            # è¯„ä¼°é¡µé¢çŠ¶æ€
            is_doc_page = '/wiki/' in current_url and '?' in current_url
            has_enough_links = len(left_links) >= 10
            
            self.logger.info("ğŸ“Š é¡µé¢çŠ¶æ€åˆ†æ")
            self.logger.info("-" * 30)
            self.logger.info(f"ğŸ“„ é¡µé¢æ ‡é¢˜: {page_title[:60]}...")
            self.logger.info(f"ğŸ”— é¡µé¢æ€»é“¾æ¥: {len(all_links)} ä¸ª")
            self.logger.info(f"ğŸ‘ˆ å·¦ä¾§åŒºåŸŸé“¾æ¥: {len(left_links)} ä¸ª")
            
            # çŠ¶æ€åˆ¤æ–­
            if is_doc_page:
                self.logger.info("âŒ é¡µé¢ç±»å‹: æ–‡æ¡£è¯¦æƒ…é¡µï¼ˆä¸é€‚åˆéå†ï¼‰")
            elif has_enough_links:
                self.logger.info("âœ… é¡µé¢ç±»å‹: çœ‹èµ·æ¥åƒç›®å½•é¡µé¢")
            else:
                self.logger.info("âš ï¸ é¡µé¢ç±»å‹: ç›®å½•é¡µé¢ä½†é“¾æ¥è¾ƒå°‘")
            
            self.logger.info("")
            
            if left_links:
                self.logger.info("ğŸ“‹ å‘ç°çš„å·¦ä¾§é“¾æ¥ï¼ˆå‰5ä¸ªï¼‰:")
                for i, link in enumerate(left_links[:5], 1):
                    self.logger.info(f"   {i}. {link['text'][:40]}")
                    
                if len(left_links) > 5:
                    self.logger.info(f"   ... è¿˜æœ‰ {len(left_links) - 5} ä¸ªé“¾æ¥")
            else:
                self.logger.info("âŒ å·¦ä¾§åŒºåŸŸæœªå‘ç°å¯éå†çš„é“¾æ¥")
            
            self.logger.info("")
            
            # æ ¹æ®åˆ†æç»“æœç»™å‡ºå…·ä½“å»ºè®®
            if is_doc_page:
                self.logger.info("ğŸ¯ è§£å†³æ–¹æ¡ˆ: è¿™æ˜¯æ–‡æ¡£é˜…è¯»é¡µé¢")
                self.logger.info("   ğŸ‘† ç‚¹å‡»æµè§ˆå™¨ã€è¿”å›ã€‘æŒ‰é’®")
                self.logger.info("   ğŸ  æˆ–å¯¼èˆªåˆ°çŸ¥è¯†åº“ä¸»é¡µé¢")
            elif len(left_links) < 3:
                self.logger.info("ğŸ¯ è§£å†³æ–¹æ¡ˆ: å½“å‰é¡µé¢é“¾æ¥å¤ªå°‘")
                self.logger.info("   ğŸ“‚ æ£€æŸ¥å·¦ä¾§ç›®å½•æ ‘æ˜¯å¦éœ€è¦å±•å¼€")
                self.logger.info("   ğŸ“‹ ç¡®ä¿å½“å‰é¡µé¢æ˜¾ç¤ºæ–‡æ¡£åˆ—è¡¨")
            else:
                self.logger.info("ğŸ¯ æƒ…å†µ: é¡µé¢ç»“æ„å¯èƒ½ä¸åŒ¹é…")
                self.logger.info("   ğŸ” è¯·æ£€æŸ¥é¡µé¢æ˜¯å¦ä¸ºæ ‡å‡†çš„é£ä¹¦çŸ¥è¯†åº“ç•Œé¢")
            
        except Exception as e:
            self.logger.error(f"é¡µé¢è¯Šæ–­å¤±è´¥: {e}")
    
    def recursive_traverse_directory(self, level: int = 0, visited_texts: set = None, path: list = None, resume_mode: bool = False):
        """é€’å½’éå†å¤šå±‚çº§ç›®å½•ç»“æ„"""
        if visited_texts is None:
            visited_texts = set()
        if path is None:
            path = []
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ–­ç‚¹ç»­ä¼ 
        if level == 0 and not resume_mode:
            resume_progress = self.check_resume_progress()
            if resume_progress:
                resume_path, resume_name = resume_progress
                self.logger.info(f"ğŸ”„ æ£€æµ‹åˆ°ä¸Šæ¬¡ä¸­æ–­ä½ç½®: {resume_path} - {resume_name}")
                
                response = input(f"æ˜¯å¦ä» '{resume_name}' ä½ç½®ç»§ç»­ï¼Ÿ(y/n): ").strip().lower()
                if response == 'y' or response == 'yes':
                    return self.start_from_resume_position(resume_path, resume_name)
                else:
                    self.logger.info("ğŸ“ é€‰æ‹©é‡æ–°å¼€å§‹ï¼Œå°†æ¸…ç©ºç°æœ‰è¿›åº¦")
                    # æ¸…ç©ºCSVæ–‡ä»¶ï¼Œé‡æ–°å¼€å§‹
                    self.clear_csv_file()
        
        max_depth = 10  # é˜²æ­¢æ— é™é€’å½’
        if level > max_depth:
            self.logger.warning(f"âš ï¸ è¾¾åˆ°æœ€å¤§é€’å½’æ·±åº¦ {max_depth}ï¼Œåœæ­¢éå†")
            return
        
        indent = "  " * level
        self.logger.info(f"{indent}ğŸŒ² å¼€å§‹ç¬¬ {level + 1} å±‚ç›®å½•éå†...")
        
        try:
            # é‡æ–°è·å–å½“å‰å±‚çº§çš„æ‰€æœ‰ç›®å½•é¡¹ï¼ˆè§£å†³stale elementé—®é¢˜ï¼‰
            current_items = self.find_sidebar_items_fresh()
            
            if not current_items:
                self.logger.info(f"{indent}ğŸ“­ ç¬¬ {level + 1} å±‚æœªæ‰¾åˆ°æ–°çš„ç›®å½•é¡¹")
                return
            
            # è¿‡æ»¤å·²è®¿é—®è¿‡çš„é¡¹ç›®ï¼ˆåŸºäºæ–‡æœ¬å†…å®¹ï¼‰
            new_items = []
            for item in current_items:
                item_text = item['name']
                if item_text not in visited_texts:
                    new_items.append(item)
                    visited_texts.add(item_text)
            
            self.logger.info(f"{indent}ğŸ“‹ ç¬¬ {level + 1} å±‚å‘ç° {len(new_items)} ä¸ªæ–°ç›®å½•é¡¹")
            
            for i, item in enumerate(new_items, 1):
                item_name = item['name']
                
                # ç”Ÿæˆè·¯å¾„å¼æ ‡è¯†
                current_path = path + [i]
                path_str = "-".join(map(str, current_path))
                
                self.logger.info(f"{indent}ğŸ“„ [{path_str}] å¤„ç†: {item_name}")
                
                # è®¿é—®é¢‘ç‡æ§åˆ¶
                if self.stats.get("successful_access", 0) > 0 or i > 1:
                    delay = self.wait_with_respect()
                
                try:
                    # é‡æ–°è·å–å…ƒç´ ï¼ˆé¿å…stale referenceï¼‰
                    fresh_element = self.find_element_by_text(item_name)
                    if not fresh_element:
                        self.logger.warning(f"{indent}âš ï¸ æ— æ³•é‡æ–°å®šä½å…ƒç´ : {item_name}")
                        continue
                    
                    # ç‚¹å‡»å…ƒç´ 
                    click_success = self.click_element_safe(fresh_element, item_name)
                    if not click_success:
                        self.logger.warning(f"{indent}âŒ ç‚¹å‡»å¤±è´¥: {item_name}")
                        self.failed_items.append({
                            'name': item_name,
                            'level': level + 1,
                            'reason': 'ç‚¹å‡»å¤±è´¥',
                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        })
                        continue
                    
                    # ç­‰å¾…é¡µé¢å“åº”
                    time.sleep(2)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰é¡µé¢å˜åŒ–ï¼ˆURLæˆ–æ ‡é¢˜æ”¹å˜ï¼‰
                    current_url = self.driver.current_url
                    current_title = self.driver.title
                    
                    # ã€ç¬¬ä¸€æ­¥ï¼šå…ˆè®°å½•çˆ¶ç›®å½•ã€‘
                    page_info = self.extract_page_info()
                    if page_info:
                        page_info['directory_item'] = item_name
                        page_info['level'] = level + 1
                        page_info['index'] = path_str  # ä½¿ç”¨è·¯å¾„å­—ç¬¦ä¸²ä½œä¸ºåºå·
                        
                        self.access_log.append(page_info)
                        self.stats["successful_access"] = self.stats.get("successful_access", 0) + 1
                        
                        # ç«‹å³ä¿å­˜åˆ°CSVæ–‡ä»¶
                        self.save_single_record_to_csv(page_info)
                        
                        self.logger.info(f"{indent}âœ… æˆåŠŸè®°å½•çˆ¶é¡¹: {current_title[:50]}...")
                    
                    # ã€å¯é€‰ï¼šä¸‹è½½å½“å‰æ–‡æ¡£ã€‘
                    if hasattr(self, 'enable_download') and self.enable_download:
                        self.attempt_download_current_document(indent, item_name)
                    
                    # ã€ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥å¹¶å¤„ç†å­ç›®å½•ã€‘
                    time.sleep(1)
                    items_after_click = self.find_sidebar_items_fresh()
                    
                    # å¦‚æœç‚¹å‡»åå‡ºç°æ–°é¡¹ç›®ï¼Œè¯´æ˜å½“å‰é¡¹æœ‰å­ç›®å½•
                    if len(items_after_click) > len(current_items):
                        self.logger.info(f"{indent}ğŸ” å‘ç° {item_name} çš„å­ç›®å½•ï¼Œå¼€å§‹é€’å½’...")
                        
                        # é€’å½’å¤„ç†å­ç›®å½•ï¼Œçˆ¶è·¯å¾„æ˜¯current_path
                        self.recursive_traverse_directory(level + 1, visited_texts, current_path, resume_mode=True)
                        
                        # é€’å½’è¿”å›åé‡æ–°è·å–DOMçŠ¶æ€ï¼ˆå­ç›®å½•å¯èƒ½å·²æ”¶èµ·ï¼‰
                        current_items = self.find_sidebar_items_fresh()
                        self.logger.info(f"{indent}ğŸ”„ å®Œæˆ {item_name} å­ç›®å½•å¤„ç†ï¼Œç»§ç»­åŒçº§éå†...")
                    
                except Exception as e:
                    self.logger.error(f"{indent}âŒ å¤„ç†é¡¹ç›® '{item_name}' æ—¶å‡ºé”™: {e}")
                    self.failed_items.append({
                        'name': item_name,
                        'level': level + 1,
                        'reason': str(e),
                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    })
                    continue
            
            self.logger.info(f"{indent}âœ… ç¬¬ {level + 1} å±‚éå†å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"{indent}âŒ ç¬¬ {level + 1} å±‚éå†å¤±è´¥: {e}")