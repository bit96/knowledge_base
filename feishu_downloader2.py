#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é£ä¹¦æ–‡æ¡£è‡ªåŠ¨ä¸‹è½½å™¨
è‡ªåŠ¨åŒ–æ‰¹é‡ä¸‹è½½é£ä¹¦æ–‡æ¡£å¹¶è®°å½•ä¸‹è½½ä¿¡æ¯
"""

import os
import csv
import json
import time
import random
import logging
import threading
import base64
import re
from datetime import datetime
from typing import List, Dict, Optional, Tuple, Set
from urllib.parse import urlparse, urljoin
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
import pandas as pd
from hotkey_controller import HotkeyController, DownloadState
from floating_ui import FloatingUI


class FeishuDownloader:
    def __init__(self, download_dir: str = "/Users/abc/PycharmProjects/knowledge_base/.venv/output", 
                 debug_mode: bool = False):
        self.download_dir = download_dir
        self.debug_mode = debug_mode
        self.csv_file = "download_log.csv"
        self.progress_file = "progress.json"
        self.log_file = "download.log"
        self.screenshot_dir = os.path.join(download_dir, "debug_screenshots")
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.setup_logging()
        
        # åˆå§‹åŒ–ä¸‹è½½ç»Ÿè®¡
        self.stats = {
            "total_processed": 0,
            "successful_downloads": 0,
            "failed_downloads": 0,
            "skipped_documents": 0
        }
        
        # æ‰¹æ¬¡è®¡æ•°å™¨
        self.batch_counter = 0
        
        # Chromeé©±åŠ¨
        self.driver = None
        
        # å¿«æ·é”®æ§åˆ¶å™¨
        self.hotkey_controller = None
        self.floating_ui = None
        
        # æ§åˆ¶æ ‡å¿—
        self._stop_requested = False
        self._control_lock = threading.Lock()
        
        # è°ƒè¯•é…ç½®
        self.debug_config = {
            "save_screenshots": debug_mode,
            "detailed_logging": debug_mode,
            "interactive_mode": False,
            "max_links_to_analyze": 50
        }
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.download_dir, exist_ok=True)
        if debug_mode:
            os.makedirs(self.screenshot_dir, exist_ok=True)
        
        # åˆå§‹åŒ–CSVæ–‡ä»¶
        self.init_csv_file()
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def init_csv_file(self):
        """åˆå§‹åŒ–CSVè®°å½•æ–‡ä»¶"""
        if not os.path.exists(self.csv_file):
            with open(self.csv_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['æ–‡æ¡£æ ‡é¢˜', 'URL', 'ä¸‹è½½æ—¶é—´', 'çŠ¶æ€'])
            self.logger.info(f"åˆ›å»ºCSVè®°å½•æ–‡ä»¶: {self.csv_file}")
    
    def save_progress(self, current_index: int, document_list: List[Dict]):
        """ä¿å­˜å½“å‰è¿›åº¦"""
        progress_data = {
            "current_index": current_index,
            "total_documents": len(document_list),
            "stats": self.stats,
            "timestamp": datetime.now().isoformat()
        }
        
        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
    
    def load_progress(self) -> Optional[Dict]:
        """åŠ è½½ä¸Šæ¬¡è¿›åº¦"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError) as e:
                self.logger.warning(f"æ— æ³•åŠ è½½è¿›åº¦æ–‡ä»¶: {e}")
        return None
    
    def setup_chrome_driver(self):
        """è®¾ç½®Chromeæµè§ˆå™¨é©±åŠ¨ - å¢å¼ºç‰ˆ"""
        try:
            self.logger.info("æ­£åœ¨è®¾ç½®Chromeæµè§ˆå™¨è¿æ¥...")
            
            # åŸºç¡€Chromeé€‰é¡¹
            chrome_options = Options()
            
            # ä¼˜åŒ–Chromeæ€§èƒ½å’Œç¨³å®šæ€§
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--disable-web-security")
            chrome_options.add_argument("--allow-running-insecure-content")
            chrome_options.add_argument("--disable-extensions")
            
            # ä¿®å¤è¿æ¥æ± é—®é¢˜
            chrome_options.add_argument("--max-connections-per-host=10")
            chrome_options.add_argument("--max-concurrent-tab-loads=4")
            
            # è®¾ç½®ä¸‹è½½ç›®å½•
            prefs = {
                "download.default_directory": self.download_dir,
                "download.prompt_for_download": False,
                "download.directory_upgrade": True,
                "safebrowsing.enabled": True,
                # ç¦ç”¨å›¾ç‰‡åŠ è½½ä»¥æé«˜é€Ÿåº¦ï¼ˆå¯é€‰ï¼‰
                "profile.managed_default_content_settings.images": 2 if not self.debug_mode else 1,
                # ç¦ç”¨é€šçŸ¥
                "profile.default_content_setting_values.notifications": 2
            }
            chrome_options.add_experimental_option("prefs", prefs)
            
            # å°è¯•è¿æ¥åˆ°ç°æœ‰Chromeä¼šè¯
            success = False
            
            # æ–¹å¼1: è¿æ¥åˆ°è°ƒè¯•ç«¯å£9222
            if not success:
                success = self._try_connect_debug_port(chrome_options, "9222")
            
            # æ–¹å¼2: å°è¯•å…¶ä»–å¸¸ç”¨ç«¯å£
            if not success:
                for port in ["9223", "9224", "9225"]:
                    if self._try_connect_debug_port(chrome_options, port):
                        success = True
                        break
            
            # æ–¹å¼3: å¯åŠ¨æ–°çš„Chromeä¼šè¯
            if not success:
                success = self._start_new_chrome_session(chrome_options)
            
            if not success:
                raise Exception("æ— æ³•åˆ›å»ºæˆ–è¿æ¥Chromeä¼šè¯")
            
            # è®¾ç½®ç­‰å¾…æ—¶é—´å’Œè¿æ¥å‚æ•°
            self.driver.implicitly_wait(5)  # å‡å°‘éšå¼ç­‰å¾…æ—¶é—´
            
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            self.driver.set_page_load_timeout(30)
            
            # æµ‹è¯•è¿æ¥ç¨³å®šæ€§
            self._test_chrome_connection()
            
            # åˆå§‹åŒ–æµ®åŠ¨UI
            self.floating_ui = FloatingUI(self.driver)
            
            self.logger.info("âœ… Chromeæµè§ˆå™¨è®¾ç½®å®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Chromeé©±åŠ¨è®¾ç½®å¤±è´¥: {e}")
            if self.debug_mode:
                import traceback
                self.logger.error(traceback.format_exc())
            return False
    
    def _try_connect_debug_port(self, chrome_options: Options, port: str) -> bool:
        """å°è¯•è¿æ¥åˆ°æŒ‡å®šè°ƒè¯•ç«¯å£"""
        try:
            debug_options = Options()
            # å¤åˆ¶åŸºç¡€é€‰é¡¹
            for arg in chrome_options.arguments:
                debug_options.add_argument(arg)
            for key, value in chrome_options.experimental_options.items():
                debug_options.add_experimental_option(key, value)
            
            # è®¾ç½®è°ƒè¯•åœ°å€
            debug_options.add_experimental_option("debuggerAddress", f"127.0.0.1:{port}")
            
            self.driver = webdriver.Chrome(options=debug_options)
            self.logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ°ç°æœ‰Chromeä¼šè¯ (ç«¯å£ {port})")
            return True
            
        except WebDriverException as e:
            self.logger.debug(f"ç«¯å£ {port} è¿æ¥å¤±è´¥: {e}")
            return False
        except Exception as e:
            self.logger.debug(f"ç«¯å£ {port} è¿æ¥å‡ºé”™: {e}")
            return False
    
    def _start_new_chrome_session(self, chrome_options: Options) -> bool:
        """å¯åŠ¨æ–°çš„Chromeä¼šè¯"""
        try:
            self.logger.info("å¯åŠ¨æ–°çš„Chromeä¼šè¯...")
            
            # æ¸…é™¤è°ƒè¯•åœ°å€é€‰é¡¹
            new_options = Options()
            for arg in chrome_options.arguments:
                new_options.add_argument(arg)
            
            # åªä¿ç•™édebuggerAddressçš„é€‰é¡¹
            for key, value in chrome_options.experimental_options.items():
                if key != "debuggerAddress":
                    new_options.add_experimental_option(key, value)
            
            self.driver = webdriver.Chrome(options=new_options)
            self.logger.info("âœ… æ–°Chromeä¼šè¯å¯åŠ¨æˆåŠŸ")
            self.logger.warning("âš ï¸  è¯·ç¡®ä¿åœ¨æ–°æ‰“å¼€çš„æµè§ˆå™¨ä¸­ç™»å½•é£ä¹¦è´¦å·å¹¶å¯¼èˆªåˆ°æ–‡æ¡£åˆ—è¡¨é¡µé¢")
            return True
            
        except Exception as e:
            self.logger.error(f"å¯åŠ¨æ–°Chromeä¼šè¯å¤±è´¥: {e}")
            return False
    
    def _test_chrome_connection(self):
        """æµ‹è¯•Chromeè¿æ¥ç¨³å®šæ€§"""
        try:
            # æµ‹è¯•åŸºæœ¬æ“ä½œ
            current_url = self.driver.current_url
            title = self.driver.title
            
            self.logger.debug(f"Chromeè¿æ¥æµ‹è¯•é€šè¿‡ - URL: {current_url[:50]}...")
            self.logger.debug(f"é¡µé¢æ ‡é¢˜: {title[:30]}...")
            
            # æµ‹è¯•JavaScriptæ‰§è¡Œ
            ready_state = self.driver.execute_script("return document.readyState")
            self.logger.debug(f"é¡µé¢çŠ¶æ€: {ready_state}")
            
        except Exception as e:
            self.logger.warning(f"Chromeè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            raise
    
    def repair_chrome_connection(self) -> bool:
        """ä¿®å¤Chromeè¿æ¥"""
        try:
            self.logger.info("å°è¯•ä¿®å¤Chromeè¿æ¥...")
            
            # æµ‹è¯•å½“å‰è¿æ¥
            if self.driver:
                try:
                    self.driver.current_url
                    self.logger.info("Chromeè¿æ¥æ­£å¸¸ï¼Œæ— éœ€ä¿®å¤")
                    return True
                except:
                    self.logger.warning("æ£€æµ‹åˆ°Chromeè¿æ¥é—®é¢˜ï¼Œé‡æ–°å»ºç«‹è¿æ¥")
            
            # é‡æ–°è®¾ç½®è¿æ¥
            old_driver = self.driver
            self.driver = None
            
            if old_driver:
                try:
                    old_driver.quit()
                except:
                    pass
            
            # é‡æ–°å»ºç«‹è¿æ¥
            success = self.setup_chrome_driver()
            
            if success:
                self.logger.info("âœ… Chromeè¿æ¥ä¿®å¤æˆåŠŸ")
            else:
                self.logger.error("âŒ Chromeè¿æ¥ä¿®å¤å¤±è´¥")
            
            return success
            
        except Exception as e:
            self.logger.error(f"Chromeè¿æ¥ä¿®å¤è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    def wait_for_page_load(self, timeout: int = 30):
        """ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½"""
        try:
            WebDriverWait(self.driver, timeout).until(
                lambda driver: driver.execute_script("return document.readyState") == "complete"
            )
            # é¢å¤–ç­‰å¾…ç¡®ä¿åŠ¨æ€å†…å®¹åŠ è½½å®Œæˆ
            time.sleep(random.uniform(2, 4))
            return True
        except TimeoutException:
            self.logger.warning("é¡µé¢åŠ è½½è¶…æ—¶")
            return False
    
    def wait_for_dynamic_content(self, timeout: int = 30) -> bool:
        """æ™ºèƒ½ç­‰å¾…åŠ¨æ€å†…å®¹åŠ è½½"""
        try:
            # 1. ç­‰å¾…DOMå®Œæˆ
            WebDriverWait(self.driver, timeout).until(
                lambda driver: driver.execute_script("return document.readyState") == "complete"
            )
            
            # 2. ç­‰å¾…å¯èƒ½çš„AJAXè¯·æ±‚å®Œæˆ
            WebDriverWait(self.driver, 10).until(
                lambda driver: driver.execute_script("return window.jQuery ? jQuery.active == 0 : true")
            )
            
            # 3. ç­‰å¾…React/Vueç»„ä»¶æ¸²æŸ“ï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰loadingçŠ¶æ€ï¼‰
            try:
                WebDriverWait(self.driver, 5).until_not(
                    EC.presence_of_element_located((By.CSS_SELECTOR, 
                        "[class*='loading'], [class*='spinner'], [class*='skeleton']"))
                )
            except TimeoutException:
                pass  # æ²¡æœ‰loadingå…ƒç´ æ˜¯æ­£å¸¸çš„
            
            # 4. é¢å¤–ç­‰å¾…ç¡®ä¿å†…å®¹ç¨³å®š
            time.sleep(random.uniform(1, 3))
            
            self.logger.debug("åŠ¨æ€å†…å®¹åŠ è½½å®Œæˆ")
            return True
            
        except TimeoutException:
            self.logger.warning("åŠ¨æ€å†…å®¹åŠ è½½è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ")
            return False
        except Exception as e:
            self.logger.warning(f"ç­‰å¾…åŠ¨æ€å†…å®¹æ—¶å‡ºé”™: {e}")
            return False
    
    def take_screenshot(self, filename_suffix: str = "") -> Optional[str]:
        """ä¿å­˜é¡µé¢æˆªå›¾ç”¨äºè°ƒè¯•"""
        if not self.debug_config["save_screenshots"] or not self.driver:
            return None
            
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"debug_{timestamp}_{filename_suffix}.png"
            filepath = os.path.join(self.screenshot_dir, filename)
            
            self.driver.save_screenshot(filepath)
            self.logger.debug(f"æˆªå›¾å·²ä¿å­˜: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.warning(f"æˆªå›¾ä¿å­˜å¤±è´¥: {e}")
            return None
    
    def diagnose_page(self) -> Dict:
        """è¯Šæ–­å½“å‰é¡µé¢ï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯"""
        try:
            # åŸºæœ¬é¡µé¢ä¿¡æ¯
            current_url = self.driver.current_url
            page_title = self.driver.title
            page_source_length = len(self.driver.page_source)
            
            # URLåˆ†æ
            parsed_url = urlparse(current_url)
            domain = parsed_url.netloc
            path = parsed_url.path
            
            # æ£€æµ‹é¡µé¢ç±»å‹
            page_type = self._detect_page_type(current_url, page_title)
            
            # åˆ†æé¡µé¢ä¸­çš„æ‰€æœ‰é“¾æ¥
            all_links = self._analyze_all_links()
            
            # æ£€æµ‹å¯èƒ½çš„æ–‡æ¡£å®¹å™¨
            containers = self._detect_document_containers()
            
            # ä¿å­˜æˆªå›¾
            screenshot_path = self.take_screenshot("page_diagnosis")
            
            diagnosis = {
                "timestamp": datetime.now().isoformat(),
                "url": current_url,
                "domain": domain,
                "path": path,
                "title": page_title,
                "page_type": page_type,
                "page_source_length": page_source_length,
                "total_links": len(all_links),
                "potential_doc_links": len([link for link in all_links if self._is_potential_doc_link(link)]),
                "containers_found": len(containers),
                "screenshot": screenshot_path,
                "link_patterns": self._analyze_link_patterns(all_links),
                "containers": containers[:5],  # åªä¿å­˜å‰5ä¸ªå®¹å™¨ä¿¡æ¯
                "sample_links": all_links[:10]  # åªä¿å­˜å‰10ä¸ªé“¾æ¥ä½œä¸ºæ ·æœ¬
            }
            
            # è¾“å‡ºè¯Šæ–­ä¿¡æ¯
            self._print_diagnosis(diagnosis)
            
            return diagnosis
            
        except Exception as e:
            self.logger.error(f"é¡µé¢è¯Šæ–­å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _detect_page_type(self, url: str, title: str) -> str:
        """æ£€æµ‹é¡µé¢ç±»å‹"""
        url_lower = url.lower()
        title_lower = title.lower()
        
        if '/wiki/' in url_lower or 'wiki' in title_lower:
            return "çŸ¥è¯†åº“/Wikié¡µé¢"
        elif '/docs/' in url_lower or '/docx/' in url_lower:
            return "æ–‡æ¡£é¡µé¢"
        elif '/sheets/' in url_lower:
            return "è¡¨æ ¼é¡µé¢"
        elif '/space/' in url_lower:
            return "ç©ºé—´é¡µé¢"
        elif '/drive/' in url_lower or '/file/' in url_lower:
            return "æ–‡ä»¶é©±åŠ¨å™¨é¡µé¢"
        elif 'feishu' in url_lower or 'lark' in url_lower:
            return "é£ä¹¦é¡µé¢"
        else:
            return "æœªçŸ¥é¡µé¢ç±»å‹"
    
    def _analyze_all_links(self) -> List[Dict]:
        """åˆ†æé¡µé¢ä¸­çš„æ‰€æœ‰é“¾æ¥"""
        try:
            links = []
            elements = self.driver.find_elements(By.TAG_NAME, "a")
            
            for element in elements[:self.debug_config["max_links_to_analyze"]]:
                try:
                    href = element.get_attribute('href')
                    text = element.text.strip()
                    title = element.get_attribute('title') or ""
                    
                    if href:
                        links.append({
                            "href": href,
                            "text": text,
                            "title": title,
                            "is_visible": element.is_displayed(),
                            "tag_name": element.tag_name
                        })
                except:
                    continue
                    
            return links
            
        except Exception as e:
            self.logger.warning(f"é“¾æ¥åˆ†æå¤±è´¥: {e}")
            return []
    
    def _detect_document_containers(self) -> List[Dict]:
        """æ£€æµ‹å¯èƒ½åŒ…å«æ–‡æ¡£çš„å®¹å™¨å…ƒç´ """
        try:
            containers = []
            
            # å¸¸è§çš„å®¹å™¨é€‰æ‹©å™¨
            container_selectors = [
                "[class*='file']",
                "[class*='doc']",
                "[class*='item']",
                "[class*='list']",
                "[class*='table']",
                "[data-testid]",
                ".lark-table-row",
                ".file-list-item"
            ]
            
            for selector in container_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        container_info = {
                            "selector": selector,
                            "count": len(elements),
                            "visible_count": len([e for e in elements if e.is_displayed()]),
                            "sample_text": elements[0].text.strip()[:100] if elements else ""
                        }
                        containers.append(container_info)
                except:
                    continue
                    
            return containers
            
        except Exception as e:
            self.logger.warning(f"å®¹å™¨æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _is_potential_doc_link(self, link: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ½œåœ¨çš„æ–‡æ¡£é“¾æ¥"""
        href = link.get("href", "").lower()
        text = link.get("text", "").lower()
        
        # URLæ¨¡å¼æ£€æµ‹
        doc_patterns = [
            r'/docs?/', r'/docx/', r'/sheets?/', r'/wiki/', 
            r'/file/', r'/document/', r'/space/'
        ]
        
        if any(re.search(pattern, href) for pattern in doc_patterns):
            return True
            
        # æ–‡æœ¬æ¨¡å¼æ£€æµ‹
        if any(keyword in text for keyword in ['æ–‡æ¡£', 'doc', 'è¡¨æ ¼', 'sheet', 'æ¼”ç¤º']):
            return True
            
        return False
    
    def _analyze_link_patterns(self, links: List[Dict]) -> Dict:
        """åˆ†æé“¾æ¥æ¨¡å¼"""
        patterns = {}
        
        for link in links:
            href = link.get("href", "")
            if href:
                # æå–åŸŸåå’Œè·¯å¾„æ¨¡å¼
                try:
                    parsed = urlparse(href)
                    domain = parsed.netloc
                    path_parts = [part for part in parsed.path.split('/') if part]
                    
                    if domain:
                        patterns.setdefault("domains", {}).setdefault(domain, 0)
                        patterns["domains"][domain] += 1
                    
                    if path_parts:
                        first_part = path_parts[0]
                        patterns.setdefault("path_patterns", {}).setdefault(first_part, 0)
                        patterns["path_patterns"][first_part] += 1
                        
                except:
                    continue
                    
        return patterns
    
    def _print_diagnosis(self, diagnosis: Dict):
        """æ‰“å°è¯Šæ–­ä¿¡æ¯"""
        if not self.debug_config["detailed_logging"]:
            return
            
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“‹ é¡µé¢è¯Šæ–­æŠ¥å‘Š")
        self.logger.info("=" * 60)
        self.logger.info(f"ğŸ”— URL: {diagnosis.get('url')}")
        self.logger.info(f"ğŸ“„ æ ‡é¢˜: {diagnosis.get('title')}")
        self.logger.info(f"ğŸ·ï¸  é¡µé¢ç±»å‹: {diagnosis.get('page_type')}")
        self.logger.info(f"ğŸ“Š é¡µé¢æºç é•¿åº¦: {diagnosis.get('page_source_length')} å­—ç¬¦")
        self.logger.info(f"ğŸ”— æ€»é“¾æ¥æ•°: {diagnosis.get('total_links')}")
        self.logger.info(f"ğŸ“„ æ½œåœ¨æ–‡æ¡£é“¾æ¥: {diagnosis.get('potential_doc_links')}")
        self.logger.info(f"ğŸ“¦ å®¹å™¨æ•°é‡: {diagnosis.get('containers_found')}")
        
        if diagnosis.get('screenshot'):
            self.logger.info(f"ğŸ“¸ æˆªå›¾: {diagnosis.get('screenshot')}")
        
        # é“¾æ¥æ¨¡å¼ä¿¡æ¯
        patterns = diagnosis.get('link_patterns', {})
        if patterns.get('domains'):
            self.logger.info("ğŸŒ åŸŸååˆ†å¸ƒ:")
            for domain, count in sorted(patterns['domains'].items(), key=lambda x: x[1], reverse=True)[:5]:
                self.logger.info(f"   {domain}: {count} ä¸ªé“¾æ¥")
        
        if patterns.get('path_patterns'):
            self.logger.info("ğŸ›¤ï¸  è·¯å¾„æ¨¡å¼:")
            for path, count in sorted(patterns['path_patterns'].items(), key=lambda x: x[1], reverse=True)[:5]:
                self.logger.info(f"   /{path}/: {count} ä¸ªé“¾æ¥")
        
        # å®¹å™¨ä¿¡æ¯
        containers = diagnosis.get('containers', [])
        if containers:
            self.logger.info("ğŸ“¦ å‘ç°çš„å®¹å™¨:")
            for container in containers[:3]:
                self.logger.info(f"   {container['selector']}: {container['visible_count']}/{container['count']} å¯è§")
        
        self.logger.info("=" * 60)
    
    def get_document_links(self) -> List[Dict]:
        """è·å–å½“å‰é¡µé¢çš„æ–‡æ¡£é“¾æ¥åˆ—è¡¨ - å¢å¼ºç‰ˆ"""
        try:
            # ä½¿ç”¨æ™ºèƒ½ç­‰å¾…
            if not self.wait_for_dynamic_content():
                self.logger.warning("é¡µé¢åŠ¨æ€å†…å®¹åŠ è½½å¯èƒ½æœªå®Œæˆï¼Œç»§ç»­å°è¯•...")
            
            # å¦‚æœå¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œå…ˆè¿›è¡Œé¡µé¢è¯Šæ–­
            if self.debug_mode:
                diagnosis = self.diagnose_page()
                self.logger.info(f"é¡µé¢è¯Šæ–­å®Œæˆï¼Œå‘ç° {diagnosis.get('potential_doc_links', 0)} ä¸ªæ½œåœ¨æ–‡æ¡£é“¾æ¥")
            
            # å¤šç­–ç•¥æŸ¥æ‰¾æ–‡æ¡£é“¾æ¥
            document_links = []
            
            # ç­–ç•¥1: å¢å¼ºç‰ˆé€‰æ‹©å™¨æŸ¥æ‰¾
            document_links.extend(self._find_links_by_enhanced_selectors())
            
            # ç­–ç•¥2: æ™ºèƒ½é“¾æ¥åˆ†æ
            if not document_links:
                document_links.extend(self._find_links_by_intelligent_analysis())
            
            # ç­–ç•¥3: é€šç”¨é“¾æ¥è¿‡æ»¤ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
            if not document_links:
                document_links.extend(self._find_links_by_pattern_matching())
            
            # å»é‡å’ŒéªŒè¯
            document_links = self._deduplicate_and_validate_links(document_links)
            
            if document_links:
                self.logger.info(f"âœ… æˆåŠŸæ‰¾åˆ° {len(document_links)} ä¸ªæ–‡æ¡£é“¾æ¥")
                if self.debug_config["detailed_logging"]:
                    self._log_found_links(document_links)
            else:
                self.logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£é“¾æ¥")
                if self.debug_mode:
                    self._suggest_troubleshooting()
                
            return document_links
            
        except Exception as e:
            self.logger.error(f"è·å–æ–‡æ¡£é“¾æ¥å¤±è´¥: {e}")
            if self.debug_mode:
                self.take_screenshot("get_links_error")
            return []
    
    def _find_links_by_enhanced_selectors(self) -> List[Dict]:
        """ç­–ç•¥1: ä½¿ç”¨å¢å¼ºç‰ˆé€‰æ‹©å™¨æŸ¥æ‰¾"""
        document_links = []
        
        # 2024å¹´æœ€æ–°é£ä¹¦ç•Œé¢é€‰æ‹©å™¨
        enhanced_selectors = [
            # æ–°ç‰ˆé£ä¹¦æ–‡æ¡£é“¾æ¥æ¨¡å¼
            "a[href*='/wiki/']", "a[href*='/space/']", "a[href*='/file/']",
            "a[href*='/document/']", "a[href*='/base/']",
            
            # ä¼ ç»Ÿæ–‡æ¡£é“¾æ¥
            "a[href*='/docs/']", "a[href*='/docx/']", "a[href*='/sheets/']",
            
            # React/Vueç»„ä»¶é€‰æ‹©å™¨
            "[data-testid*='file']", "[data-testid*='document']", "[data-testid*='doc']",
            "[data-testid*='wiki']", "[data-testid*='space']",
            
            # æ–°ç‰ˆUIç»„ä»¶ç±»å
            ".lark-table-row a", ".file-list-item a", ".doc-list-item a",
            ".wiki-list-item a", ".space-item a",
            
            # é€šç”¨å®¹å™¨å†…çš„é“¾æ¥
            "[class*='file'] a", "[class*='doc'] a", "[class*='item'] a",
            "[class*='list'] a[href]", "[class*='table'] a[href]",
            
            # Ant Design / å…¶ä»–UIæ¡†æ¶
            ".ant-table-row a", ".ant-list-item a",
            
            # è‡ªå®šä¹‰å±æ€§
            "[role='row'] a", "[role='gridcell'] a", "[role='link'][href]"
        ]
        
        for selector in enhanced_selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    found_links = []
                    for element in elements:
                        link_info = self._extract_link_info(element)
                        if link_info and self._is_valid_document_link(link_info):
                            found_links.append(link_info)
                    
                    if found_links:
                        self.logger.info(f"é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(found_links)} ä¸ªæœ‰æ•ˆé“¾æ¥")
                        document_links.extend(found_links)
                        # æ‰¾åˆ°æœ‰æ•ˆé“¾æ¥å°±åœæ­¢ï¼ˆä¼˜å…ˆçº§ç­–ç•¥ï¼‰
                        if len(document_links) >= 5:  # æ‰¾åˆ°è¶³å¤Ÿçš„é“¾æ¥å°±åœæ­¢
                            break
                        
            except Exception as e:
                self.logger.debug(f"é€‰æ‹©å™¨ '{selector}' æ‰§è¡Œå¤±è´¥: {e}")
                continue
        
        return document_links
    
    def _find_links_by_intelligent_analysis(self) -> List[Dict]:
        """ç­–ç•¥2: æ™ºèƒ½åˆ†æé¡µé¢ä¸­çš„æ‰€æœ‰é“¾æ¥"""
        try:
            all_links = self.driver.find_elements(By.TAG_NAME, "a")
            document_links = []
            
            self.logger.info(f"å¼€å§‹æ™ºèƒ½åˆ†æ {len(all_links)} ä¸ªé“¾æ¥...")
            
            for element in all_links:
                try:
                    link_info = self._extract_link_info(element)
                    if link_info and self._is_potential_document_link_advanced(link_info):
                        document_links.append(link_info)
                except:
                    continue
            
            if document_links:
                self.logger.info(f"æ™ºèƒ½åˆ†ææ‰¾åˆ° {len(document_links)} ä¸ªæ–‡æ¡£é“¾æ¥")
            
            return document_links
            
        except Exception as e:
            self.logger.warning(f"æ™ºèƒ½é“¾æ¥åˆ†æå¤±è´¥: {e}")
            return []
    
    def _find_links_by_pattern_matching(self) -> List[Dict]:
        """ç­–ç•¥3: é€šç”¨æ¨¡å¼åŒ¹é…ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰"""
        try:
            # è·å–æ‰€æœ‰é“¾æ¥è¿›è¡Œæ¨¡å¼åŒ¹é…
            all_links = self.driver.find_elements(By.XPATH, "//a[@href]")
            document_links = []
            
            self.logger.info(f"æ‰§è¡Œå…œåº•æ–¹æ¡ˆï¼Œåˆ†æ {len(all_links)} ä¸ªé“¾æ¥çš„æ¨¡å¼...")
            
            for element in all_links:
                try:
                    href = element.get_attribute('href')
                    if href and self._matches_document_url_pattern(href):
                        link_info = self._extract_link_info(element)
                        if link_info:
                            document_links.append(link_info)
                except:
                    continue
            
            if document_links:
                self.logger.info(f"æ¨¡å¼åŒ¹é…æ‰¾åˆ° {len(document_links)} ä¸ªå¯èƒ½çš„æ–‡æ¡£é“¾æ¥")
            
            return document_links
            
        except Exception as e:
            self.logger.warning(f"æ¨¡å¼åŒ¹é…å¤±è´¥: {e}")
            return []
    
    def _extract_link_info(self, element) -> Optional[Dict]:
        """æå–é“¾æ¥ä¿¡æ¯"""
        try:
            href = element.get_attribute('href')
            if not href:
                return None
                
            text = element.text.strip()
            title = element.get_attribute('title') or ""
            aria_label = element.get_attribute('aria-label') or ""
            
            # åˆå¹¶æ‰€æœ‰å¯ç”¨çš„æ–‡æœ¬ä¿¡æ¯
            display_text = text or title or aria_label or "æœªçŸ¥æ–‡æ¡£"
            
            return {
                'title': display_text,
                'url': href,
                'element': element,
                'text': text,
                'title_attr': title,
                'aria_label': aria_label,
                'is_visible': element.is_displayed(),
                'tag_name': element.tag_name
            }
            
        except Exception:
            return None
    
    def _is_valid_document_link(self, link_info: Dict) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ–‡æ¡£é“¾æ¥"""
        href = link_info.get('url', '').lower()
        text = link_info.get('title', '').lower()
        
        # æ’é™¤æ˜æ˜¾ä¸æ˜¯æ–‡æ¡£çš„é“¾æ¥
        exclude_patterns = [
            'javascript:', 'mailto:', '#', 'tel:',
            '/login', '/logout', '/settings', '/profile',
            '.jpg', '.png', '.gif', '.pdf', '.mp4'
        ]
        
        if any(pattern in href for pattern in exclude_patterns):
            return False
        
        # å¿…é¡»æ˜¯å¯è§çš„é“¾æ¥ï¼ˆé™¤éæ˜¯è°ƒè¯•æ¨¡å¼ï¼‰
        if not self.debug_mode and not link_info.get('is_visible', False):
            return False
        
        # å¿…é¡»æœ‰ä¸€å®šé•¿åº¦çš„URL
        if len(href) < 10:
            return False
            
        # å¿…é¡»æœ‰æ–‡æœ¬å†…å®¹æˆ–è€…åŒ¹é…æ–‡æ¡£URLæ¨¡å¼
        if not text and not self._matches_document_url_pattern(href):
            return False
        
        return True
    
    def _is_potential_document_link_advanced(self, link_info: Dict) -> bool:
        """é«˜çº§æ–‡æ¡£é“¾æ¥åˆ¤æ–­"""
        href = link_info.get('url', '').lower()
        text = link_info.get('title', '').lower()
        
        # å…ˆè¿›è¡ŒåŸºç¡€éªŒè¯
        if not self._is_valid_document_link(link_info):
            return False
        
        # URLæ¨¡å¼åŒ¹é… - æ›´å…¨é¢çš„æ¨¡å¼
        doc_url_patterns = [
            r'/wiki/', r'/docs?/', r'/docx/', r'/sheets?/', r'/base/',
            r'/file/', r'/document/', r'/space/', r'/drive/',
            r'/knowledge/', r'/kb/', r'/pages?/'
        ]
        
        url_match = any(re.search(pattern, href) for pattern in doc_url_patterns)
        
        # æ–‡æœ¬å†…å®¹åŒ¹é…
        text_keywords = [
            'æ–‡æ¡£', 'document', 'doc', 'è¡¨æ ¼', 'sheet', 'excel',
            'wiki', 'çŸ¥è¯†', 'knowledge', 'æ¼”ç¤º', 'presentation',
            'ç¬”è®°', 'note', 'é¡µé¢', 'page'
        ]
        
        text_match = any(keyword in text for keyword in text_keywords)
        
        # ç»¼åˆåˆ¤æ–­
        if url_match:
            return True
        if text_match and len(text) > 2:
            return True
        
        # ç‰¹æ®Šæƒ…å†µï¼šé£ä¹¦åŸŸåä¸‹çš„é“¾æ¥ç»™äºˆé¢å¤–æƒé‡
        if any(domain in href for domain in ['feishu.cn', 'larksuite.com', 'bytedance.net']):
            return url_match or text_match
        
        return False
    
    def _matches_document_url_pattern(self, url: str) -> bool:
        """æ£€æŸ¥URLæ˜¯å¦åŒ¹é…æ–‡æ¡£æ¨¡å¼"""
        url_lower = url.lower()
        
        # é£ä¹¦æ–‡æ¡£URLæ¨¡å¼
        feishu_patterns = [
            r'feishu\.cn/wiki/',
            r'feishu\.cn/docs?/',
            r'feishu\.cn/sheets?/',
            r'feishu\.cn/file/',
            r'feishu\.cn/base/',
            r'larksuite\.com/wiki/',
            r'larksuite\.com/docs?/',
        ]
        
        return any(re.search(pattern, url_lower) for pattern in feishu_patterns)
    
    def _deduplicate_and_validate_links(self, links: List[Dict]) -> List[Dict]:
        """å»é‡å’Œæœ€ç»ˆéªŒè¯é“¾æ¥"""
        seen_urls = set()
        unique_links = []
        
        for link in links:
            url = link.get('url', '')
            if url not in seen_urls:
                seen_urls.add(url)
                unique_links.append(link)
        
        self.logger.debug(f"å»é‡åä¿ç•™ {len(unique_links)} ä¸ªå”¯ä¸€é“¾æ¥")
        return unique_links
    
    def _log_found_links(self, links: List[Dict]):
        """è®°å½•æ‰¾åˆ°çš„é“¾æ¥è¯¦æƒ…"""
        self.logger.info("ğŸ“‹ å‘ç°çš„æ–‡æ¡£é“¾æ¥:")
        for i, link in enumerate(links[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            title = link.get('title', '')[:50] + ('...' if len(link.get('title', '')) > 50 else '')
            url = link.get('url', '')[:80] + ('...' if len(link.get('url', '')) > 80 else '')
            self.logger.info(f"   {i}. {title}")
            self.logger.info(f"      {url}")
        
        if len(links) > 10:
            self.logger.info(f"   ... è¿˜æœ‰ {len(links) - 10} ä¸ªé“¾æ¥")
    
    def _suggest_troubleshooting(self):
        """æä¾›æ•…éšœæ’é™¤å»ºè®®"""
        self.logger.info("ğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        self.logger.info("1. ç¡®è®¤å½“å‰é¡µé¢æ˜¯é£ä¹¦æ–‡æ¡£åˆ—è¡¨é¡µé¢")
        self.logger.info("2. æ£€æŸ¥é¡µé¢æ˜¯å¦å®Œå…¨åŠ è½½ï¼ˆç­‰å¾…åŠ¨ç”»ç»“æŸï¼‰")
        self.logger.info("3. å°è¯•æ‰‹åŠ¨æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹")
        self.logger.info("4. æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•æˆ–æƒé™")
        self.logger.info("5. æŸ¥çœ‹è°ƒè¯•æˆªå›¾äº†è§£é¡µé¢çŠ¶æ€")
        
        current_url = self.driver.current_url if self.driver else "æœªçŸ¥"
        self.logger.info(f"å½“å‰URL: {current_url}")
        
        # ä¿å­˜é¢å¤–çš„è°ƒè¯•æˆªå›¾
        self.take_screenshot("troubleshooting")
    
    def download_document(self, doc_info: Dict) -> bool:
        """ä¸‹è½½å•ä¸ªæ–‡æ¡£"""
        max_retries = 3
        retry_interval = 60  # 1åˆ†é’Ÿ
        
        for attempt in range(max_retries):
            try:
                self.logger.info(f"å¼€å§‹ä¸‹è½½æ–‡æ¡£: {doc_info['title']} (å°è¯• {attempt + 1}/{max_retries})")
                
                # ç‚¹å‡»æ–‡æ¡£é“¾æ¥è¿›å…¥è¯¦æƒ…é¡µ
                if 'element' in doc_info:
                    # æ»šåŠ¨åˆ°å…ƒç´ å¯è§
                    self.driver.execute_script("arguments[0].scrollIntoView(true);", doc_info['element'])
                    time.sleep(1)
                    
                    # ç‚¹å‡»é“¾æ¥
                    doc_info['element'].click()
                else:
                    # ç›´æ¥å¯¼èˆªåˆ°URL
                    self.driver.get(doc_info['url'])
                
                # ç­‰å¾…æ–‡æ¡£é¡µé¢åŠ è½½
                if not self.wait_for_page_load():
                    raise TimeoutException("æ–‡æ¡£é¡µé¢åŠ è½½è¶…æ—¶")
                
                # è·å–å®é™…çš„æ–‡æ¡£æ ‡é¢˜å’ŒURL
                actual_title = self.driver.title
                actual_url = self.driver.current_url
                
                # æŸ¥æ‰¾å¹¶ç‚¹å‡»æ›´å¤šæ“ä½œæŒ‰é’®ï¼ˆä¸‰ä¸ªç‚¹ï¼‰
                more_button_selectors = [
                    "[data-testid='more-actions']",
                    ".more-actions-btn",
                    "[aria-label*='æ›´å¤š']",
                    "button[title*='æ›´å¤š']",
                    ".header-more-btn",
                    "button:has(svg):last-child"  # æœ€åä¸€ä¸ªåŒ…å«SVGçš„æŒ‰é’®
                ]
                
                more_button = None
                for selector in more_button_selectors:
                    try:
                        more_button = WebDriverWait(self.driver, 5).until(
                            EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
                        )
                        break
                    except TimeoutException:
                        continue
                
                if not more_button:
                    raise NoSuchElementException("æœªæ‰¾åˆ°æ›´å¤šæ“ä½œæŒ‰é’®")
                
                # ç‚¹å‡»æ›´å¤šæŒ‰é’®
                more_button.click()
                time.sleep(1)
                
                # æŸ¥æ‰¾å¹¶ç‚¹å‡»ä¸‹è½½é€‰é¡¹
                download_selectors = [
                    "[data-testid='download']",
                    "button:contains('ä¸‹è½½')",
                    "a:contains('ä¸‹è½½')",
                    "[aria-label*='ä¸‹è½½']",
                    ".download-btn"
                ]
                
                download_button = None
                for selector in download_selectors:
                    try:
                        download_button = WebDriverWait(self.driver, 5).until(
                            EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
                        )
                        break
                    except TimeoutException:
                        continue
                
                if not download_button:
                    raise NoSuchElementException("æœªæ‰¾åˆ°ä¸‹è½½æŒ‰é’®")
                
                # ç‚¹å‡»ä¸‹è½½æŒ‰é’®
                download_button.click()
                time.sleep(2)
                
                # é€‰æ‹©ä¸‹è½½æ ¼å¼ï¼ˆæ ¹æ®æ–‡æ¡£ç±»å‹ï¼‰
                self.select_download_format()
                
                # ç­‰å¾…ä¸‹è½½å¼€å§‹
                time.sleep(3)
                
                # è®°å½•æˆåŠŸä¸‹è½½
                self.record_download(actual_title, actual_url, "æˆåŠŸ")
                self.stats["successful_downloads"] += 1
                
                self.logger.info(f"æ–‡æ¡£ä¸‹è½½æˆåŠŸ: {actual_title}")
                
                # è¿”å›åˆ°åˆ—è¡¨é¡µé¢
                self.driver.back()
                self.wait_for_page_load()
                
                return True
                
            except Exception as e:
                self.logger.warning(f"æ–‡æ¡£ä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                
                if attempt < max_retries - 1:
                    self.logger.info(f"ç­‰å¾… {retry_interval} ç§’åé‡è¯•...")
                    time.sleep(retry_interval)
                    # ç¡®ä¿å›åˆ°åˆ—è¡¨é¡µé¢
                    try:
                        self.driver.back()
                        self.wait_for_page_load()
                    except:
                        pass
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè®°å½•å¤±è´¥
                    self.record_download(doc_info['title'], doc_info.get('url', ''), "å¤±è´¥")
                    self.stats["failed_downloads"] += 1
                    return False
        
        return False
    
    def select_download_format(self):
        """æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©ä¸‹è½½æ ¼å¼"""
        try:
            # æŸ¥æ‰¾æ ¼å¼é€‰æ‹©é€‰é¡¹
            format_selectors = [
                "button:contains('Word')",
                "button:contains('Excel')", 
                "button:contains('PDF')",
                "[data-format='docx']",
                "[data-format='xlsx']",
                "[data-format='pdf']"
            ]
            
            # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨æ ¼å¼
            for selector in format_selectors:
                try:
                    format_button = WebDriverWait(self.driver, 3).until(
                        EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
                    )
                    format_button.click()
                    self.logger.debug(f"é€‰æ‹©ä¸‹è½½æ ¼å¼: {selector}")
                    return
                except TimeoutException:
                    continue
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šæ ¼å¼ï¼Œå°è¯•ç‚¹å‡»ç¬¬ä¸€ä¸ªä¸‹è½½é€‰é¡¹
            self.logger.debug("ä½¿ç”¨é»˜è®¤ä¸‹è½½æ ¼å¼")
            
        except Exception as e:
            self.logger.debug(f"æ ¼å¼é€‰æ‹©å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼: {e}")
    
    def record_download(self, title: str, url: str, status: str):
        """è®°å½•ä¸‹è½½ä¿¡æ¯åˆ°CSV"""
        try:
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            with open(self.csv_file, 'a', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow([title, url, timestamp, status])
                
        except Exception as e:
            self.logger.error(f"è®°å½•ä¸‹è½½ä¿¡æ¯å¤±è´¥: {e}")
    
    def _on_start_callback(self):
        """å¯åŠ¨å›è°ƒå‡½æ•°"""
        with self._control_lock:
            self._stop_requested = False
        self.logger.info("æ”¶åˆ°å¯åŠ¨ä¿¡å·ï¼Œå¼€å§‹è‡ªåŠ¨åŒ–æ“ä½œ")
        if self.floating_ui:
            self.floating_ui.update_status(DownloadState.RUNNING)
    
    def _on_stop_callback(self):
        """åœæ­¢å›è°ƒå‡½æ•°"""
        with self._control_lock:
            self._stop_requested = True
        self.logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæš‚åœè‡ªåŠ¨åŒ–æ“ä½œ")
        if self.floating_ui:
            self.floating_ui.update_status(DownloadState.STOPPED)
    
    def _is_stop_requested(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢"""
        with self._control_lock:
            return self._stop_requested
    
    def _wait_for_start_or_stop(self, timeout: Optional[float] = None) -> bool:
        """ç­‰å¾…å¯åŠ¨ä¿¡å·ï¼Œå¦‚æœæ”¶åˆ°åœæ­¢ä¿¡å·åˆ™è¿”å›False"""
        if not self.hotkey_controller:
            return True  # æ²¡æœ‰æ§åˆ¶å™¨æ—¶é»˜è®¤ç»§ç»­
        
        start_time = time.time()
        while True:
            if self.hotkey_controller.is_running():
                return True
            if self._is_stop_requested():
                return False
            if timeout and (time.time() - start_time) > timeout:
                return False
            time.sleep(0.1)
    
    def anti_crawl_delay(self):
        """é˜²åçˆ¬å»¶è¿Ÿ"""
        base_delay = 10  # åŸºç¡€å»¶è¿Ÿ10ç§’
        random_delay = random.uniform(0, 20)  # éšæœº0-20ç§’
        total_delay = base_delay + random_delay
        
        self.logger.info(f"é˜²åçˆ¬å»¶è¿Ÿ: {total_delay:.1f} ç§’")
        time.sleep(total_delay)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰¹æ¬¡ä¼‘æ¯
        self.batch_counter += 1
        if self.batch_counter >= 100:
            self.logger.info("å·²å¤„ç†100ä¸ªæ–‡æ¡£ï¼Œä¼‘æ¯30åˆ†é’Ÿ...")
            time.sleep(30 * 60)  # 30åˆ†é’Ÿ
            self.batch_counter = 0
    
    def run(self, start_index: int = 0, enable_hotkeys: bool = True):
        """è¿è¡Œä¸»ä¸‹è½½æµç¨‹ - å¢å¼ºç‰ˆ"""
        try:
            self.logger.info("=" * 60)
            self.logger.info("ğŸš€ é£ä¹¦æ–‡æ¡£è‡ªåŠ¨ä¸‹è½½å™¨ v2.0 å¯åŠ¨")
            self.logger.info("=" * 60)
            
            if self.debug_mode:
                self.logger.info("ğŸ”§ è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
                self.logger.info(f"ğŸ“¸ æˆªå›¾ä¿å­˜ç›®å½•: {self.screenshot_dir}")
            
            # è®¾ç½®Chromeé©±åŠ¨ï¼ˆå¢å¼ºç‰ˆï¼‰
            if not self.setup_chrome_driver():
                self.logger.error("âŒ Chromeé©±åŠ¨è®¾ç½®å¤±è´¥")
                if self.debug_mode:
                    self._interactive_debug_chrome_issue()
                return
            
            # åˆå§‹åŒ–å¿«æ·é”®æ§åˆ¶å™¨
            if enable_hotkeys:
                self.hotkey_controller = HotkeyController(
                    on_start_callback=self._on_start_callback,
                    on_stop_callback=self._on_stop_callback
                )
                self.hotkey_controller.start_listening()
                self.logger.info("ğŸ® å¿«æ·é”®æ§åˆ¶å·²å¯ç”¨: åŒå‡»ç©ºæ ¼é”®å¯åŠ¨ï¼ŒESCé”®åœæ­¢")
            
            # æ³¨å…¥æ‚¬æµ®UIå¹¶è®¾ç½®ä¸ºå‡†å¤‡çŠ¶æ€
            if self.floating_ui:
                self.floating_ui.inject_ui()
                self.floating_ui.update_status(DownloadState.READY)
                self.logger.info("ğŸ›ï¸ æ‚¬æµ®çŠ¶æ€UIå·²æ¿€æ´»")
            
            self.logger.info(f"ğŸ“ ä¸‹è½½ç›®å½•: {self.download_dir}")
            
            # è·å–æ–‡æ¡£åˆ—è¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰
            self.logger.info("ğŸ” æ­£åœ¨æ‰«ææ–‡æ¡£åˆ—è¡¨...")
            document_links = self.get_document_links()
            
            if not document_links:
                self.logger.error("âŒ æœªæ‰¾åˆ°å¯ä¸‹è½½çš„æ–‡æ¡£")
                if self.debug_mode:
                    self._interactive_debug_no_links()
                return
            
            self.logger.info(f"âœ… å‘ç° {len(document_links)} ä¸ªæ–‡æ¡£")
            
            # è°ƒè¯•æ¨¡å¼ä¸‹çš„äº¤äº’å¼ç¡®è®¤
            if self.debug_mode and self.debug_config.get("interactive_mode", False):
                if not self._interactive_confirm_links(document_links):
                    self.logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                    return
            
            if enable_hotkeys:
                self.logger.info("â³ ç­‰å¾…ç”¨æˆ·æ“ä½œ...")
                self.logger.info("   åŒå‡»ç©ºæ ¼é”®å¼€å§‹ä¸‹è½½ï¼ŒESCé”®å¯éšæ—¶åœæ­¢")
                
                # ç­‰å¾…å¯åŠ¨ä¿¡å·
                if not self._wait_for_start_or_stop():
                    self.logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                    return
            
            self.logger.info("ğŸš€ å¼€å§‹æ‰¹é‡ä¸‹è½½...")
            
            # ä»æŒ‡å®šç´¢å¼•å¼€å§‹å¤„ç†
            for i in range(start_index, len(document_links)):
                # æ£€æŸ¥åœæ­¢è¯·æ±‚å’Œè¿æ¥çŠ¶æ€
                if enable_hotkeys and self._is_stop_requested():
                    self.logger.info(f"â¸ï¸  ç”¨æˆ·åœæ­¢æ“ä½œï¼Œå·²å¤„ç† {i}/{len(document_links)} ä¸ªæ–‡æ¡£")
                    break
                
                # æ£€æŸ¥Chromeè¿æ¥çŠ¶æ€
                if not self._check_and_repair_connection():
                    self.logger.error("Chromeè¿æ¥æ— æ³•ä¿®å¤ï¼Œç»ˆæ­¢ä¸‹è½½")
                    break
                
                doc_info = document_links[i]
                self.logger.info(f"ğŸ“„ å¤„ç†æ–‡æ¡£ {i+1}/{len(document_links)}: {doc_info['title'][:50]}...")
                
                # æ£€æŸ¥UIå¹¶ä¿®å¤ï¼ˆå¦‚æœé¡µé¢åˆ·æ–°ï¼‰
                if self.floating_ui:
                    self.floating_ui.check_and_repair()
                
                # ä¿å­˜è¿›åº¦
                self.save_progress(i, document_links)
                
                # ä¸‹è½½æ–‡æ¡£ï¼ˆå¸¦å¢å¼ºé”™è¯¯å¤„ç†ï¼‰
                success = self._download_document_with_recovery(doc_info)
                self.stats["total_processed"] += 1
                
                if success:
                    self.logger.info(f"âœ… æ–‡æ¡£ {i+1} ä¸‹è½½æˆåŠŸ")
                else:
                    self.logger.error(f"âŒ æ–‡æ¡£ {i+1} ä¸‹è½½å¤±è´¥")
                    if self.debug_mode:
                        self.take_screenshot(f"download_failed_{i}")
                
                # é˜²åçˆ¬å»¶è¿Ÿï¼ˆé™¤äº†æœ€åä¸€ä¸ªæ–‡æ¡£ï¼‰
                if i < len(document_links) - 1:
                    self.anti_crawl_delay()
                    
                    # åœ¨å»¶è¿Ÿè¿‡ç¨‹ä¸­æ£€æŸ¥æ˜¯å¦è¦æ±‚åœæ­¢
                    if enable_hotkeys and self._is_stop_requested():
                        self.logger.info("â¸ï¸  åœ¨å»¶è¿Ÿè¿‡ç¨‹ä¸­æ”¶åˆ°åœæ­¢ä¿¡å·")
                        break
                
                # å¦‚æœåœæ­¢çŠ¶æ€ä¸‹ç­‰å¾…é‡æ–°å¯åŠ¨
                if enable_hotkeys and self.hotkey_controller and self.hotkey_controller.is_stopped():
                    self.logger.info("â¸ï¸  ç­‰å¾…ç”¨æˆ·é‡æ–°å¯åŠ¨...")
                    if not self._wait_for_start_or_stop():
                        self.logger.info("ç”¨æˆ·ç¡®è®¤åœæ­¢")
                        break
            
            # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
            self.print_final_stats()
            
        except KeyboardInterrupt:
            self.logger.info("â¸ï¸  ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
            self.print_final_stats()
        except Exception as e:
            self.logger.error(f"ğŸ’¥ è¿è¡Œæ—¶é”™è¯¯: {e}")
            if self.debug_mode:
                import traceback
                self.logger.error(traceback.format_exc())
                self.take_screenshot("runtime_error")
            raise
        finally:
            # æ¸…ç†èµ„æº
            self._cleanup_resources()
    
    def _interactive_debug_chrome_issue(self):
        """äº¤äº’å¼è°ƒè¯•Chromeè¿æ¥é—®é¢˜"""
        self.logger.info("ğŸ”§ Chromeè¿æ¥é—®é¢˜äº¤äº’å¼è°ƒè¯•:")
        self.logger.info("1. è¯·æ£€æŸ¥Chromeæ˜¯å¦åœ¨è°ƒè¯•æ¨¡å¼è¿è¡Œ:")
        self.logger.info("   /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222")
        self.logger.info("2. æ£€æŸ¥ç«¯å£9222æ˜¯å¦è¢«å ç”¨")
        self.logger.info("3. å°è¯•é‡å¯Chromeæµè§ˆå™¨")
        
        try:
            response = input("\næ˜¯å¦è¦æˆ‘å°è¯•å…¶ä»–ç«¯å£? (y/n): ").strip().lower()
            if response == 'y':
                for port in ["9223", "9224", "9225"]:
                    self.logger.info(f"å°è¯•ç«¯å£ {port}...")
                    if self._try_connect_debug_port(Options(), port):
                        self.logger.info(f"âœ… ç«¯å£ {port} è¿æ¥æˆåŠŸ!")
                        return
                self.logger.error("âŒ æ‰€æœ‰ç«¯å£éƒ½æ— æ³•è¿æ¥")
        except (EOFError, KeyboardInterrupt):
            self.logger.info("è·³è¿‡äº¤äº’å¼è°ƒè¯•")
    
    def _interactive_debug_no_links(self):
        """äº¤äº’å¼è°ƒè¯•æ— æ³•æ‰¾åˆ°é“¾æ¥çš„é—®é¢˜"""
        self.logger.info("ğŸ”§ æ— æ³•æ‰¾åˆ°æ–‡æ¡£é“¾æ¥ - äº¤äº’å¼è°ƒè¯•:")
        
        try:
            response = input("\næ˜¯å¦è¦æŸ¥çœ‹é¡µé¢è¯¦ç»†ä¿¡æ¯? (y/n): ").strip().lower()
            if response == 'y':
                diagnosis = self.diagnose_page()
                self.logger.info("é¡µé¢è¯Šæ–­å®Œæˆï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹çš„è¯Šæ–­æŠ¥å‘Š")
                
                response = input("\næ˜¯å¦è¦å¯ç”¨äº¤äº’æ¨¡å¼æ‰‹åŠ¨ç¡®è®¤é“¾æ¥? (y/n): ").strip().lower()
                if response == 'y':
                    self.debug_config["interactive_mode"] = True
                    self.logger.info("âœ… äº¤äº’æ¨¡å¼å·²å¯ç”¨")
                    
        except (EOFError, KeyboardInterrupt):
            self.logger.info("è·³è¿‡äº¤äº’å¼è°ƒè¯•")
    
    def _interactive_confirm_links(self, document_links: List[Dict]) -> bool:
        """äº¤äº’å¼ç¡®è®¤æ‰¾åˆ°çš„é“¾æ¥"""
        try:
            self.logger.info("ğŸ” äº¤äº’å¼é“¾æ¥ç¡®è®¤æ¨¡å¼:")
            self.logger.info(f"å‘ç° {len(document_links)} ä¸ªæ½œåœ¨æ–‡æ¡£é“¾æ¥:")
            
            for i, link in enumerate(document_links[:10], 1):
                title = link.get('title', '').strip()[:50]
                url = link.get('url', '')[:60]
                self.logger.info(f"  {i}. {title}")
                self.logger.info(f"     {url}")
            
            if len(document_links) > 10:
                self.logger.info(f"  ... è¿˜æœ‰ {len(document_links) - 10} ä¸ªé“¾æ¥")
            
            response = input("\nè¿™äº›é“¾æ¥çœ‹èµ·æ¥æ­£ç¡®å—? (y/n): ").strip().lower()
            return response == 'y'
            
        except (EOFError, KeyboardInterrupt):
            return False
    
    def _check_and_repair_connection(self) -> bool:
        """æ£€æŸ¥å¹¶ä¿®å¤Chromeè¿æ¥"""
        try:
            if self.driver:
                # ç®€å•çš„è¿æ¥æµ‹è¯•
                self.driver.current_url
                return True
        except:
            self.logger.warning("æ£€æµ‹åˆ°Chromeè¿æ¥é—®é¢˜ï¼Œå°è¯•ä¿®å¤...")
            return self.repair_chrome_connection()
        
        return False
    
    def _download_document_with_recovery(self, doc_info: Dict) -> bool:
        """å¸¦æ¢å¤æœºåˆ¶çš„æ–‡æ¡£ä¸‹è½½"""
        max_connection_retries = 2
        
        for attempt in range(max_connection_retries):
            try:
                return self.download_document(doc_info)
            except WebDriverException as e:
                if "disconnected" in str(e).lower() or "connection" in str(e).lower():
                    self.logger.warning(f"è¿æ¥ä¸­æ–­ (å°è¯• {attempt + 1}/{max_connection_retries}), å°è¯•ä¿®å¤...")
                    if attempt < max_connection_retries - 1:
                        if self.repair_chrome_connection():
                            continue
                        else:
                            break
                else:
                    raise
            except Exception as e:
                self.logger.error(f"ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°éè¿æ¥é”™è¯¯: {e}")
                break
        
        return False
    
    def _cleanup_resources(self):
        """æ¸…ç†èµ„æº"""
        self.logger.info("ğŸ§¹ æ¸…ç†èµ„æº...")
        
        if self.hotkey_controller:
            try:
                self.hotkey_controller.stop_listening()
                self.logger.debug("å¿«æ·é”®ç›‘å¬å·²åœæ­¢")
            except:
                pass
        
        if self.floating_ui:
            try:
                self.floating_ui.remove_ui()
                self.logger.debug("æ‚¬æµ®UIå·²ç§»é™¤")
            except:
                pass
        
        # ä¸å…³é—­æµè§ˆå™¨ï¼Œä¿æŒä¼šè¯
        if self.driver:
            self.logger.info("ğŸ’¡ Chromeä¼šè¯ä¿æŒå¼€å¯çŠ¶æ€")
        
        self.logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")
    
    def print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        self.logger.info("=" * 50)
        self.logger.info("ä¸‹è½½å®Œæˆç»Ÿè®¡:")
        self.logger.info(f"æ€»å¤„ç†æ•°é‡: {self.stats['total_processed']}")
        self.logger.info(f"æˆåŠŸä¸‹è½½: {self.stats['successful_downloads']}")
        self.logger.info(f"ä¸‹è½½å¤±è´¥: {self.stats['failed_downloads']}")
        self.logger.info(f"è·³è¿‡æ–‡æ¡£: {self.stats['skipped_documents']}")
        self.logger.info(f"CSVè®°å½•æ–‡ä»¶: {self.csv_file}")
        self.logger.info(f"ä¸‹è½½ç›®å½•: {self.download_dir}")
        self.logger.info("=" * 50)


def main():
    """ä¸»å‡½æ•° - å¢å¼ºç‰ˆ"""
    print("ğŸš€ é£ä¹¦æ–‡æ¡£è‡ªåŠ¨ä¸‹è½½å™¨ v2.0 - å¢å¼ºè°ƒè¯•ç‰ˆ")
    print("=" * 60)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒè¯•æ¨¡å¼
    debug_mode = False
    try:
        import sys
        if "--debug" in sys.argv or "-d" in sys.argv:
            debug_mode = True
            print("ğŸ”§ è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
        elif "--help" in sys.argv or "-h" in sys.argv:
            print_help()
            return
    except:
        pass
    
    # åˆå§‹åŒ–ä¸‹è½½å™¨
    downloader = FeishuDownloader(debug_mode=debug_mode)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„è¿›åº¦
    progress = downloader.load_progress()
    start_index = 0
    
    if progress:
        print(f"ğŸ“‹ å‘ç°ä¸Šæ¬¡ä¸­æ–­çš„è¿›åº¦:")
        print(f"   å·²å¤„ç†: {progress['current_index']}/{progress['total_documents']}")
        
        try:
            response = input("\næ˜¯å¦ç»§ç»­ä¸Šæ¬¡çš„ä¸‹è½½? (y/n): ").strip().lower()
            if response == 'y':
                start_index = progress['current_index']
                downloader.stats = progress.get('stats', downloader.stats)
                print(f"âœ… ä»ç¬¬ {start_index + 1} ä¸ªæ–‡æ¡£ç»§ç»­ä¸‹è½½")
            else:
                print("ğŸ”„ å°†ä»å¤´å¼€å§‹ä¸‹è½½")
        except EOFError:
            # éäº¤äº’å¼ç¯å¢ƒï¼Œé»˜è®¤ç»§ç»­ä¸Šæ¬¡è¿›åº¦
            start_index = progress['current_index']
            downloader.stats = progress.get('stats', downloader.stats)
            print(f"ğŸ¤– éäº¤äº’å¼ç¯å¢ƒï¼Œè‡ªåŠ¨ä»ç¬¬ {start_index + 1} ä¸ªæ–‡æ¡£ç»§ç»­ä¸‹è½½")
    
    # æ˜¾ç¤ºåŠŸèƒ½è¯´æ˜
    print("\nâœ¨ v2.0 å¢å¼ºåŠŸèƒ½:")
    print("ğŸ® å¿«æ·é”®æ§åˆ¶ - åŒå‡»ç©ºæ ¼é”®å¯åŠ¨ï¼ŒESCé”®åœæ­¢")
    print("ğŸ›ï¸  çŠ¶æ€æ˜¾ç¤º - é¡µé¢å·¦ä¸Šè§’æ‚¬æµ®æ¡†å®æ—¶æ˜¾ç¤ºçŠ¶æ€")
    print("ğŸ” æ™ºèƒ½è¯†åˆ« - å¤šç­–ç•¥æ–‡æ¡£é“¾æ¥è¯†åˆ«")
    print("ğŸ”§ æ•…éšœè¯Šæ–­ - è‡ªåŠ¨é¡µé¢è¯Šæ–­å’Œæˆªå›¾")
    print("ğŸ›¡ï¸  è¿æ¥ä¿®å¤ - è‡ªåŠ¨æ£€æµ‹å’Œä¿®å¤Chromeè¿æ¥")
    
    if debug_mode:
        print("\nğŸ”§ è°ƒè¯•æ¨¡å¼åŠŸèƒ½:")
        print("ğŸ“¸ è‡ªåŠ¨æˆªå›¾ - å¤±è´¥æ—¶è‡ªåŠ¨ä¿å­˜é¡µé¢æˆªå›¾")
        print("ğŸ“‹ è¯¦ç»†æ—¥å¿— - æ˜¾ç¤ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯")
        print("ğŸ” é¡µé¢è¯Šæ–­ - è‡ªåŠ¨åˆ†æé¡µé¢ç»“æ„å’Œé“¾æ¥")
        print("ğŸ’¬ äº¤äº’è°ƒè¯• - é—®é¢˜å‡ºç°æ—¶æä¾›äº¤äº’å¼è°ƒè¯•é€‰é¡¹")
    
    print("\nğŸ“‹ ä½¿ç”¨å‰è¯·ç¡®ä¿:")
    print("1. âœ… Chromeæµè§ˆå™¨å·²ç™»å½•é£ä¹¦è´¦å·")
    print("2. âœ… å½“å‰é¡µé¢ä¸ºéœ€è¦ä¸‹è½½çš„æ–‡æ¡£åˆ—è¡¨é¡µé¢")
    print("3. âœ… ç½‘ç»œè¿æ¥æ­£å¸¸ç¨³å®š")
    
    if debug_mode:
        print("4. ğŸ”§ å¦‚é‡é—®é¢˜å°†è‡ªåŠ¨å¯ç”¨è°ƒè¯•åŠŸèƒ½")
    
    try:
        response = input("\næŒ‰å›è½¦é”®å¯åŠ¨ç¨‹åº (æˆ–è¾“å…¥ 'q' é€€å‡º): ").strip()
        if response.lower() == 'q':
            print("ğŸ‘‹ ç¨‹åºé€€å‡º")
            return
    except EOFError:
        print("\nğŸ¤– æ£€æµ‹åˆ°éäº¤äº’å¼ç¯å¢ƒï¼Œè‡ªåŠ¨å¯åŠ¨ç¨‹åº...")
    
    print("\n" + "=" * 60)
    print("ğŸš€ ç¨‹åºå¯åŠ¨ä¸­...")
    print("=" * 60)
    
    try:
        # è¿è¡Œä¸‹è½½å™¨
        downloader.run(start_index)
    except KeyboardInterrupt:
        print("\nâ¸ï¸  ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nğŸ’¥ ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        if debug_mode:
            import traceback
            print("\nğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            print(f"\nğŸ“¸ é”™è¯¯æˆªå›¾å¯èƒ½å·²ä¿å­˜åˆ°: {downloader.screenshot_dir}")
        else:
            print("ğŸ’¡ æç¤º: ä½¿ç”¨ --debug å‚æ•°å¯è·å¾—æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯")

def print_help():
    """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
    print("ğŸš€ é£ä¹¦æ–‡æ¡£è‡ªåŠ¨ä¸‹è½½å™¨ v2.0")
    print("=" * 50)
    print("ç”¨æ³•:")
    print("  python3 feishu_downloader2.py [é€‰é¡¹]")
    print()
    print("é€‰é¡¹:")
    print("  --debug, -d    å¯ç”¨è°ƒè¯•æ¨¡å¼")
    print("  --help, -h     æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
    print()
    print("è°ƒè¯•æ¨¡å¼åŠŸèƒ½:")
    print("  ğŸ“¸ è‡ªåŠ¨æˆªå›¾ä¿å­˜")
    print("  ğŸ“‹ è¯¦ç»†æ—¥å¿—è¾“å‡º")
    print("  ğŸ” é¡µé¢ç»“æ„åˆ†æ")
    print("  ğŸ’¬ äº¤äº’å¼é—®é¢˜è¯Šæ–­")
    print("  ğŸ›¡ï¸  å¢å¼ºé”™è¯¯æ¢å¤")
    print()
    print("å¿«æ·é”®:")
    print("  åŒå‡»ç©ºæ ¼é”®  - å¯åŠ¨/ç»§ç»­ä¸‹è½½")
    print("  ESCé”®       - æš‚åœä¸‹è½½")
    print("  Ctrl+C      - é€€å‡ºç¨‹åº")
    print()
    print("ä½¿ç”¨æ­¥éª¤:")
    print("1. å¯åŠ¨Chromeè°ƒè¯•æ¨¡å¼:")
    print("   /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222")
    print("2. åœ¨Chromeä¸­ç™»å½•é£ä¹¦å¹¶å¯¼èˆªåˆ°æ–‡æ¡£åˆ—è¡¨é¡µé¢")
    print("3. è¿è¡Œæ­¤ç¨‹åº")
    print("4. åŒå‡»ç©ºæ ¼é”®å¼€å§‹ä¸‹è½½")
    print()
    print("è¾“å‡ºæ–‡ä»¶:")
    print("  download_log.csv     - ä¸‹è½½è®°å½•")
    print("  download.log         - è¯¦ç»†æ—¥å¿—")
    print("  progress.json        - è¿›åº¦æ–‡ä»¶")
    print("  debug_screenshots/   - è°ƒè¯•æˆªå›¾ (è°ƒè¯•æ¨¡å¼)")
    print("=" * 50)


if __name__ == "__main__":
    main()